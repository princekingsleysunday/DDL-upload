{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/princekingsleysunday/DDL-upload/blob/master/CNN_VGGnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGb592TrkBiY"
      },
      "outputs": [],
      "source": [
        "## VGGNet MNIST classification\n",
        "\n",
        "# import the libraries\n",
        "from keras.datasets.mnist import load_data\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from tensorflow.python.framework import ops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using VGGNet Algorithm\n",
        "\n",
        "VGG is a Convolutional Neural Network architecture, It was proposed by Karen Simonyan and Andrew Zisserman of Oxford Robotics Institute in the paper Very Deep Convolutional Networks for Large-Scale Image Recognition.\n",
        "It was submitted to Large Scale Visual Recognition Challenge 2014 and The model achieves 92.7% top-5 test accuracy in ImageNet.\n",
        "ImageNet is one the on the largest data-set available. It has 14 million hand-annotated images belonging to 1000 classes.\n",
        "\n",
        "\n",
        "The main concept is stacking of convolutional layers to create a deep neural network.\n",
        "VGG shows that the depth of the network has an important role. Deeper networks give better results.\n",
        "One drawback of VGGNet is that this network is usually big. It contains around 160M parameters. Most of the parameters are consumed in the fully connected layers."
      ],
      "metadata": {
        "id": "Jc2FMBgzwH21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data - it returns 2 tuples of digits & labels - one for\n",
        "# the train set & the other for the test set\n",
        "(train_digits, train_labels), (test_digits, test_labels) = load_data()\n",
        "#  some variables...\n",
        "image_height = train_digits.shape[1]  \n",
        "image_width = train_digits.shape[2]\n",
        "num_channels = 1  # we have grayscale images\n",
        "# NOTE: image_height == image_width == 28\n",
        "# re-shape the images data\n",
        "train_data = np.reshape(train_digits, (train_digits.shape[0], image_height, image_width, num_channels))\n",
        "test_data = np.reshape(test_digits, (test_digits.shape[0],image_height, image_width, num_channels))\n",
        "\n",
        "# re-scale the image data to values between [0,1]\n",
        "train_data = train_data.astype('float32') / 255.\n",
        "test_data = test_data.astype('float32') / 255.\n",
        "\n",
        "# one-hot encode the labels - we have 10 output classes\n",
        "\n",
        "# so 3 -> [0 0 0 1 0 0 0 0 0 0], 5 -> [0 0 0 0 0 1 0 0 0 0] & so on\n",
        "num_classes = 10\n",
        "train_labels_cat = to_categorical(train_labels,num_classes)\n",
        "test_labels_cat = to_categorical(test_labels,num_classes)\n",
        "\n",
        "# split training set into training and validation\n",
        "train_data2, val_data,train_labels_cat2,  val_labels = train_test_split(train_data, train_labels_cat, test_size=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1XHjmoQkx5S",
        "outputId": "4dcb6df3-e491-4878-bd0b-6696186f610c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print('X_train shape', X_train.shape, 'X_test shape', X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi1IPYdBk9bu",
        "outputId": "db4a3992-69ba-442e-caa0-3255c57e5043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape (60000, 28, 28) X_test shape (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "def preprocess_data(X_train, y_train, X_test, y_test):\n",
        "  # reshape images to the required size of Keras\n",
        "  X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
        "  X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
        "  \n",
        "  # convert image values from integers to floats\n",
        "  X_train = X_train.astype('float32')\n",
        "  X_test = X_test.astype('float32')\n",
        "  \n",
        "  # normalization\n",
        "  X_train = X_train/255.0\n",
        "  X_test_norm = X_test/255.0\n",
        "  \n",
        "  # One-hot encoding label \n",
        "  y_train = to_categorical(y_train)\n",
        "  y_test = to_categorical(y_test)\n",
        "  \n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "o3ZRfz10lApo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##VGGNet model\n",
        "\n",
        "from keras.layers import BatchNormalization\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Flatten, Conv2D, MaxPooling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, 3, activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
        "model.add(Conv2D(64, 3, activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128, 3, activation='relu', padding='same'))\n",
        "model.add(Conv2D(128, 3, activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(256, 3, activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, 3, activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, 3, activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(512, 3, activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, 3, activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, 3, activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(2, 1)) # default stride is 2\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(512, 3, activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, 3, activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, 3, activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(2, 1)) # default stride is 2\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "-RureZ6vlD10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='sgd',\n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "BPT-6X4YlgfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summary_history(history):\n",
        "  plt.figure(figsize = (10,6))\n",
        "  plt.plot(history.history['accuracy'], color = 'blue', label = 'train')\n",
        "  plt.plot(history.history['val_accuracy'], color = 'red', label = 'val')\n",
        "  plt.legend()\n",
        "  plt.title('Accuracy')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def train_model(model, X_train, y_train, X_test, y_test, epochs = 50, batch_size = 128):\n",
        "  # Rescaling all training and testing data\n",
        "  X_train, y_train, X_test, y_test = preprocess_data(X_train, y_train, X_test, y_test)\n",
        "  # Fitting the model on the training set\n",
        "  history = model.fit(X_train, y_train, epochs = epochs, batch_size = batch_size, \n",
        "                      steps_per_epoch = X_train.shape[0]//batch_size, \n",
        "                      validation_data = (X_test, y_test), \n",
        "                      validation_steps = X_test.shape[0]//batch_size, verbose = 1)\n",
        "  # evaluating the model\n",
        "  _, acc = model.evaluate(X_test, y_test, verbose = 1)\n",
        "  print('%.3f' % (acc * 100.0))\n",
        "  summary_history(history)\n",
        "\n",
        "# import the builtin time module\n",
        "import time\n",
        "\n",
        "# Grab Currrent Time Before Running the Code\n",
        "start = time.time()\n",
        "\n",
        "train_model(model,X_train, y_train, X_test, y_test)\n",
        "\n",
        "# Grab Currrent Time After Running the Code\n",
        "end = time.time()\n",
        "\n",
        "#Subtract Start Time from The End Time\n",
        "total_time = end - start\n",
        "print(f'it took {total_time} to train using the VGGnet model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BbeM6JOZlQF5",
        "outputId": "430f9bd5-ca69-42d3-c0b1-86b6d2525c9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "468/468 [==============================] - 38s 60ms/step - loss: 0.2119 - accuracy: 0.9397 - val_loss: 457.4115 - val_accuracy: 0.1495\n",
            "Epoch 2/50\n",
            "468/468 [==============================] - 28s 58ms/step - loss: 0.0392 - accuracy: 0.9887 - val_loss: 1091.1201 - val_accuracy: 0.1514\n",
            "Epoch 3/50\n",
            "468/468 [==============================] - 28s 59ms/step - loss: 0.0214 - accuracy: 0.9943 - val_loss: 1322.0701 - val_accuracy: 0.1839\n",
            "Epoch 4/50\n",
            "468/468 [==============================] - 28s 60ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 937.5428 - val_accuracy: 0.2903\n",
            "Epoch 5/50\n",
            "468/468 [==============================] - 29s 61ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 1034.6271 - val_accuracy: 0.1699\n",
            "Epoch 6/50\n",
            "468/468 [==============================] - 28s 60ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 880.2313 - val_accuracy: 0.3232\n",
            "Epoch 7/50\n",
            "468/468 [==============================] - 28s 60ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 886.2759 - val_accuracy: 0.2861\n",
            "Epoch 8/50\n",
            "468/468 [==============================] - 28s 61ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 919.4531 - val_accuracy: 0.2819\n",
            "Epoch 9/50\n",
            "468/468 [==============================] - 28s 60ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 878.9488 - val_accuracy: 0.3016\n",
            "Epoch 10/50\n",
            "468/468 [==============================] - 28s 60ms/step - loss: 7.4836e-04 - accuracy: 1.0000 - val_loss: 862.3981 - val_accuracy: 0.2904\n",
            "Epoch 11/50\n",
            "468/468 [==============================] - 28s 60ms/step - loss: 6.4504e-04 - accuracy: 1.0000 - val_loss: 880.9713 - val_accuracy: 0.2974\n",
            "Epoch 12/50\n",
            "468/468 [==============================] - 30s 63ms/step - loss: 5.5287e-04 - accuracy: 1.0000 - val_loss: 878.2618 - val_accuracy: 0.2826\n",
            "Epoch 13/50\n",
            "468/468 [==============================] - 28s 61ms/step - loss: 4.7077e-04 - accuracy: 1.0000 - val_loss: 854.8079 - val_accuracy: 0.2933\n",
            "Epoch 14/50\n",
            "468/468 [==============================] - 28s 60ms/step - loss: 4.1236e-04 - accuracy: 1.0000 - val_loss: 874.6617 - val_accuracy: 0.3089\n",
            "Epoch 15/50\n",
            "468/468 [==============================] - 28s 61ms/step - loss: 3.1800e-04 - accuracy: 1.0000 - val_loss: 875.5729 - val_accuracy: 0.2999\n",
            "Epoch 16/50\n",
            "468/468 [==============================] - 30s 64ms/step - loss: 2.9982e-04 - accuracy: 1.0000 - val_loss: 899.9828 - val_accuracy: 0.2812\n",
            "Epoch 17/50\n",
            "468/468 [==============================] - 30s 64ms/step - loss: 2.8245e-04 - accuracy: 1.0000 - val_loss: 891.9136 - val_accuracy: 0.2925\n",
            "Epoch 18/50\n",
            "468/468 [==============================] - 30s 64ms/step - loss: 2.5353e-04 - accuracy: 1.0000 - val_loss: 876.6199 - val_accuracy: 0.2911\n",
            "Epoch 19/50\n",
            "468/468 [==============================] - 29s 61ms/step - loss: 2.3360e-04 - accuracy: 1.0000 - val_loss: 881.9558 - val_accuracy: 0.2930\n",
            "Epoch 20/50\n",
            "468/468 [==============================] - 29s 61ms/step - loss: 2.3326e-04 - accuracy: 1.0000 - val_loss: 883.2241 - val_accuracy: 0.2924\n",
            "Epoch 21/50\n",
            "468/468 [==============================] - 28s 61ms/step - loss: 1.9770e-04 - accuracy: 1.0000 - val_loss: 890.2585 - val_accuracy: 0.2949\n",
            "Epoch 22/50\n",
            "468/468 [==============================] - 29s 61ms/step - loss: 1.8801e-04 - accuracy: 1.0000 - val_loss: 875.1678 - val_accuracy: 0.2987\n",
            "Epoch 23/50\n",
            "468/468 [==============================] - 29s 61ms/step - loss: 1.6863e-04 - accuracy: 1.0000 - val_loss: 879.1891 - val_accuracy: 0.3080\n",
            "Epoch 24/50\n",
            "468/468 [==============================] - 29s 61ms/step - loss: 1.8786e-04 - accuracy: 1.0000 - val_loss: 873.9896 - val_accuracy: 0.2994\n",
            "Epoch 25/50\n",
            "468/468 [==============================] - 29s 61ms/step - loss: 1.7512e-04 - accuracy: 1.0000 - val_loss: 876.9188 - val_accuracy: 0.2916\n",
            "Epoch 26/50\n",
            "468/468 [==============================] - 29s 61ms/step - loss: 1.3965e-04 - accuracy: 1.0000 - val_loss: 872.9363 - val_accuracy: 0.2972\n",
            "Epoch 27/50\n",
            "468/468 [==============================] - 29s 61ms/step - loss: 1.4659e-04 - accuracy: 1.0000 - val_loss: 869.5194 - val_accuracy: 0.2999\n",
            "Epoch 28/50\n",
            "468/468 [==============================] - 28s 61ms/step - loss: 1.3601e-04 - accuracy: 1.0000 - val_loss: 865.5462 - val_accuracy: 0.3063\n",
            "Epoch 29/50\n",
            "468/468 [==============================] - 28s 61ms/step - loss: 1.3384e-04 - accuracy: 1.0000 - val_loss: 865.9005 - val_accuracy: 0.3045\n",
            "Epoch 30/50\n",
            "468/468 [==============================] - 28s 61ms/step - loss: 1.3144e-04 - accuracy: 1.0000 - val_loss: 857.8952 - val_accuracy: 0.3060\n",
            "Epoch 31/50\n",
            "468/468 [==============================] - 28s 61ms/step - loss: 1.1877e-04 - accuracy: 1.0000 - val_loss: 857.9558 - val_accuracy: 0.3035\n",
            "Epoch 32/50\n",
            "468/468 [==============================] - 29s 61ms/step - loss: 1.1159e-04 - accuracy: 1.0000 - val_loss: 853.8686 - val_accuracy: 0.3082\n",
            "Epoch 33/50\n",
            "468/468 [==============================] - 29s 61ms/step - loss: 9.9704e-05 - accuracy: 1.0000 - val_loss: 853.6675 - val_accuracy: 0.3072\n",
            "Epoch 34/50\n",
            "468/468 [==============================] - 29s 61ms/step - loss: 1.0116e-04 - accuracy: 1.0000 - val_loss: 849.5635 - val_accuracy: 0.3053\n",
            "Epoch 35/50\n",
            "468/468 [==============================] - 28s 61ms/step - loss: 9.5395e-05 - accuracy: 1.0000 - val_loss: 854.8463 - val_accuracy: 0.3044\n",
            "Epoch 36/50\n",
            "468/468 [==============================] - 28s 61ms/step - loss: 9.9751e-05 - accuracy: 1.0000 - val_loss: 857.2541 - val_accuracy: 0.3041\n",
            "Epoch 37/50\n",
            "468/468 [==============================] - 29s 61ms/step - loss: 9.3147e-05 - accuracy: 1.0000 - val_loss: 856.1782 - val_accuracy: 0.3060\n",
            "Epoch 38/50\n",
            "468/468 [==============================] - 28s 60ms/step - loss: 9.6420e-05 - accuracy: 1.0000 - val_loss: 854.4909 - val_accuracy: 0.3069\n",
            "Epoch 39/50\n",
            "468/468 [==============================] - 28s 60ms/step - loss: 9.3248e-05 - accuracy: 1.0000 - val_loss: 863.2332 - val_accuracy: 0.3001\n",
            "Epoch 40/50\n",
            "468/468 [==============================] - 28s 60ms/step - loss: 9.3987e-05 - accuracy: 1.0000 - val_loss: 863.0621 - val_accuracy: 0.3062\n",
            "Epoch 41/50\n",
            "468/468 [==============================] - 29s 61ms/step - loss: 8.0090e-05 - accuracy: 1.0000 - val_loss: 864.2920 - val_accuracy: 0.3026\n",
            "Epoch 42/50\n",
            "468/468 [==============================] - 29s 61ms/step - loss: 8.5027e-05 - accuracy: 1.0000 - val_loss: 864.2350 - val_accuracy: 0.3045\n",
            "Epoch 43/50\n",
            "468/468 [==============================] - 29s 61ms/step - loss: 8.2071e-05 - accuracy: 1.0000 - val_loss: 859.6207 - val_accuracy: 0.3007\n",
            "Epoch 44/50\n",
            "468/468 [==============================] - 29s 61ms/step - loss: 8.1727e-05 - accuracy: 1.0000 - val_loss: 860.4529 - val_accuracy: 0.3026\n",
            "Epoch 45/50\n",
            "468/468 [==============================] - 28s 61ms/step - loss: 7.9008e-05 - accuracy: 1.0000 - val_loss: 864.9441 - val_accuracy: 0.2966\n",
            "Epoch 46/50\n",
            "468/468 [==============================] - 29s 61ms/step - loss: 7.5714e-05 - accuracy: 1.0000 - val_loss: 861.6006 - val_accuracy: 0.3014\n",
            "Epoch 47/50\n",
            "468/468 [==============================] - 28s 61ms/step - loss: 7.1585e-05 - accuracy: 1.0000 - val_loss: 861.9569 - val_accuracy: 0.3000\n",
            "Epoch 48/50\n",
            "468/468 [==============================] - 29s 61ms/step - loss: 6.7511e-05 - accuracy: 1.0000 - val_loss: 866.6719 - val_accuracy: 0.2992\n",
            "Epoch 49/50\n",
            "468/468 [==============================] - 29s 61ms/step - loss: 7.4865e-05 - accuracy: 1.0000 - val_loss: 868.4728 - val_accuracy: 0.2977\n",
            "Epoch 50/50\n",
            "468/468 [==============================] - 28s 60ms/step - loss: 6.7752e-05 - accuracy: 1.0000 - val_loss: 870.6787 - val_accuracy: 0.2959\n",
            "313/313 [==============================] - 4s 10ms/step - loss: 870.8909 - accuracy: 0.2957\n",
            "29.570\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it took 1467.2374544143677 to train using the VGGnet model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cm2SsRCWldVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "Accuracy on test data : 29.59\n",
        "\n",
        "It took 1467.23 sec to train the MNIST data using the VGGnet architecture"
      ],
      "metadata": {
        "id": "f1TMsnl4yaLo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A8vOZ4lNoTIl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}